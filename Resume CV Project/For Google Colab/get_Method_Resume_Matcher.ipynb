{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "KJqidW_-cxEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2a3a62-644b-432a-95e6-16021153a842"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8Txi7c_iUwx",
        "outputId": "36662fe7-c77f-4328-dd46-c198189dd816"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "GwiVtk-WdRKg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2txt\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxFOIR-hn_r1",
        "outputId": "9b49fac8-e416-47ce-e4ac-ffe2b25fe6f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3959 sha256=e10c13d291d26741fdd16c31e4bafd7349aa820a100395acae64fb978b8e2209\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, render_template\n",
        "import os\n",
        "import docx2txt\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "resumess=[]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ17-FNUoE9Q",
        "outputId": "effe451e-fdfd-4b05-ac55-ef3ac16321e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07iKcc7xYBhX",
        "outputId": "34ffe1f4-7abd-4e8a-c523-0267345c4de5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extraction Method From Google Cloud#"
      ],
      "metadata": {
        "id": "CuSdqfxhP_q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity(w1, w2):\n",
        "  w1=nlp(w1)\n",
        "  w2=nlp(w2)\n",
        "  return score(w1,w2)\n",
        "\n"
      ],
      "metadata": {
        "id": "fWn5egP4dR2w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_nouns(w1_nouns,w2_nouns):\n",
        "  w1_nouns=nlp(w1_nouns)\n",
        "  w2_nouns=nlp(w2_nouns)\n",
        "  similarity_score1=w1_nouns.similarity(w2_nouns)\n",
        "  return similarity_score1"
      ],
      "metadata": {
        "id": "BdAwUVQX0fgU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_adj(w1_adj, w2_adj):\n",
        "  w1_adjs=nlp(w1_adj)\n",
        "  w2_adjs=nlp(w2_adj)\n",
        "  similarity_score2=w1_adjs.similarity(w2_adjs)\n",
        "  return similarity_score2"
      ],
      "metadata": {
        "id": "gTPq7v5t1cEY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_verb(w1_verb, w2_verb):\n",
        "  w1_verbs=nlp(w1_verb)\n",
        "  w2_verbs=nlp(w2_verb)\n",
        "  similarity_score3=w1_verbs.similarity(w2_verbs)\n",
        "  return similarity_score3"
      ],
      "metadata": {
        "id": "yAAzxdsc4APH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(w1,w2):\n",
        "  w1_nouns=\" \".join([token.lemma_ for token in w1 if token.pos_==\"NOUN\"])\n",
        "  w2_nouns=\" \".join([token.lemma_ for token in w2 if token.pos_==\"NOUN\"])\n",
        "  w1_adj=\" \".join([token.lemma_ for token in w1 if token.pos_==\"ADJ\"])\n",
        "  w2_adj=\" \".join([token.lemma_ for token in w2 if token.pos_==\"ADJ\"])\n",
        "  w1_verb=\" \".join([token.lemma_ for token in w1 if token.pos_==\"VERB\"])\n",
        "  w2_verb=\" \".join([token.lemma_ for token in w2 if token.pos_==\"VERB\"])\n",
        "  vector1=similarity_nouns(w1_nouns,w2_nouns)\n",
        "  vector2=similarity_adj(w1_adj,w2_adj)\n",
        "  vector3=similarity_verb(w1_verb,w2_verb)\n",
        "  sum=((vector1 + vector2+ vector3)/3)\n",
        "  return sum"
      ],
      "metadata": {
        "id": "oIugpqV54Jsz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import io\n",
        "import os\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "def remove_stopwords(sen):\n",
        "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
        "    return sen_new\n",
        "\n",
        "def cleanUp(text):\n",
        "    # remove punctuations, numbers and special characters\n",
        "    clean_sentences = pd.Series([text]).str.replace(\"[^a-zA-Z]\", \" \")\n",
        "    # make alphabets lowercase\n",
        "    clean_sentences = [s.lower() for s in clean_sentences]\n",
        "    clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
        "    return clean_sentences[0]\n",
        "\n",
        "def getMethod(input: str, path: str):\n",
        "    resumess = []\n",
        "    resume_names = []\n",
        "    try:\n",
        "        # List files in the specified Google Drive folder\n",
        "        folder_id = path  # 'path'\n",
        "        results = drive_service.files().list(\n",
        "            q=f\"'{folder_id}' in parents\",\n",
        "            fields=\"files(id, name)\").execute()\n",
        "        items = results.get('files', [])\n",
        "\n",
        "        for item in items:\n",
        "            file_id = item['id']\n",
        "            file_name = item['name']\n",
        "\n",
        "            if file_name.lower().endswith('.pdf'):\n",
        "                # Download the file content\n",
        "                request = drive_service.files().get_media(fileId=file_id)\n",
        "                fh = io.BytesIO()\n",
        "                downloader = MediaIoBaseDownload(fh, request)\n",
        "                done = False\n",
        "                while done is False:\n",
        "                    status, done = downloader.next_chunk()\n",
        "\n",
        "                # Read the content\n",
        "                fh.seek(0)\n",
        "                pdf_reader = PyPDF2.PdfReader(fh)\n",
        "                Otext = \"\"\n",
        "                for page in pdf_reader.pages:\n",
        "                    Otext += page.extract_text()\n",
        "\n",
        "                cleaned_text = cleanUp(Otext)\n",
        "                resumess.append(cleaned_text)\n",
        "                resume_names.append(file_name)\n",
        "\n",
        "                print(f\"Processed: {file_name}\")\n",
        "\n",
        "            elif file_name.lower().endswith('.docx'):\n",
        "                request = drive_service.files().get_media(fileId=file_id)\n",
        "                fh = io.BytesIO()\n",
        "                downloader = MediaIoBaseDownload(fh, request)\n",
        "                done = False\n",
        "                while done is False:\n",
        "                    status, done = downloader.next_chunk()\n",
        "\n",
        "                fh.seek(0)\n",
        "                text = docx2txt.process(fh)\n",
        "\n",
        "                cleaned_text = cleanUp(text)\n",
        "                resumess.append(cleaned_text)\n",
        "                resume_names.append(file_name)\n",
        "\n",
        "                print(f\"Processed: {file_name}\")\n",
        "\n",
        "            elif file_name.lower().endswith('.txt'):\n",
        "                request = drive_service.files().get_media(fileId=file_id)\n",
        "                fh = io.BytesIO()\n",
        "                downloader = MediaIoBaseDownload(fh, request)\n",
        "                done = False\n",
        "                while done is False:\n",
        "                    status, done = downloader.next_chunk()\n",
        "\n",
        "                fh.seek(0)\n",
        "                text = fh.read().decode('utf-8', errors='ignore')\n",
        "\n",
        "                cleaned_text = cleanUp(text)\n",
        "                resumess.append(cleaned_text)\n",
        "                resume_names.append(file_name)\n",
        "\n",
        "                print(f\"Processed: {file_name}\")\n",
        "\n",
        "        print(f\"Total PDFs processed: {len(resumess)}\")\n",
        "\n",
        "        vetorizer=TfidfVectorizer().fit_transform([input] + resumess)\n",
        "        vectors=vetorizer.toarray()\n",
        "        job_vector=vectors[0]\n",
        "        resume_vectors=vectors[1:]\n",
        "        similarities=[]\n",
        "\n",
        "        for i in range(len(resumess)):\n",
        "          w=resumess[i]\n",
        "          similarities.append(similarity(input, w))\n",
        "\n",
        "        #sort similarities along with indices\n",
        "        sorted_indices = sorted(range(len(similarities)), key=similarities.__getitem__, reverse=True)\n",
        "        top_indices=sorted_indices[-5:]\n",
        "        top_resumes=[resumess[i] for i in top_indices]\n",
        "        top_resume_names = [resume_names[i] for i in top_indices]\n",
        "        similarity_scores=[round(similarities[i], 2)*100 for i in top_indices]\n",
        "\n",
        "        for name, score in zip(top_resume_names, similarity_scores):\n",
        "          print(f\"Resume: {name}, Similarity Score: {score}\")\n",
        "\n",
        "        return resumess\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# processed_resumes = getMethod('job description', '1W76QMo6XSKRLpHbHHLzgDDJuVGWznuVH')\n",
        "# print(processed_resumes)\n",
        "job_desc = \"Job Description: We are seeking a highly motivated and experienced Software Engineer to join our dynamic team. The ideal candidate will have a strong background in software development, excellent problem-solving skills, and the ability to work effectively in a collaborative environment. Key Responsibilities: - Develop, test, and maintain high-quality software applications. - Collaborate with cross-functional teams to define and design new features. - Troubleshoot and resolve software defects and issues. - Participate in code reviews to ensure adherence to coding standards and best practices. - Continuously learn and apply new technologies to improve software performance and scalability. Requirements: - Bachelor's degree in Computer Science, Engineering, or a related field. - 3+ years of experience in software development. - Proficiency in one or more programming languages (e.g., Python, Java, C++). - Experience with version control systems (e.g., Git). - Strong understanding of software development methodologies (e.g., Agile, Scrum). - Excellent communication and teamwork skills. Preferred Qualifications: - Experience with cloud platforms (e.g., AWS, Azure, Google Cloud). - Familiarity with front-end technologies (e.g., HTML, CSS, JavaScript). - Knowledge of database management systems (e.g., MySQL, PostgreSQL). - Previous experience in a fast-paced startup environment. If you are passionate about software engineering and eager to contribute to the success of a growing company, we encourage you to apply. Please submit your resume and cover letter for consideration. \"\n",
        "outputt = getMethod(job_desc , '1W76QMo6XSKRLpHbHHLzgDDJuVGWznuVH' )\n",
        "print(outputt)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8uHyA4UQFpV",
        "outputId": "e53557a2-e214-4e3a-9478-28c3860a4190"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: software developer.pdf\n",
            "Processed: backend developer.pdf\n",
            "Processed: data engineer.pdf\n",
            "Processed: graphic.docx\n",
            "Processed: Software Engineer.pdf\n",
            "Total PDFs processed: 5\n",
            "Resume: Software Engineer.pdf, Similarity Score: 86.0\n",
            "Resume: software developer.pdf, Similarity Score: 81.0\n",
            "Resume: data engineer.pdf, Similarity Score: 81.0\n",
            "Resume: graphic.docx, Similarity Score: 81.0\n",
            "Resume: backend developer.pdf, Similarity Score: 79.0\n",
            "['alice williams alicewilliams@example.com experience: - software developer innovatetech (2019 - present) - developed maintained web applications using javascript, react, node.js. - collaborated ux designers implement user -friendly interfaces. - optimized application performance improved loading times. education: - bachelor science computer science, tech university (2015 - 2019) skills: - programming languages: javascript, python, java - frameworks: react, node.js, express - tools: git, docker, jenkins', 'bob johnson bobjohnson@example.com experience: - backend developer datasolutions (2018 - present) - designed implemented restful apis using pyth django. - integrated third -party services apis. - conducted performance tuning optimization database queries. education: - master science software engineering, engineering university (2016 - 2018) skills: - programming languag es: python, java - frameworks: django, flask - tools: postgresql, redis, kubernetes', 'eve taylor evetaylor@example.com experience: - data engineer analyticspro (2018 - present) - developed etl pipelines process large datasets. - implemented data warehousing solutions using aws redshift. - collaborated data scientists design data models. education: - master science data engineering, data university (2016 - 2018) skills: - programming languages: python, sql - tools: apache spark, hadoop, airflow - cloud platforms: aws, gcp', 'david lee davidlee@example.com experience: - graphic designer creativestudio (2019 - present) - designed marketing materials, including brochures, flyers, social media graphics. - collaborated clients understand design needs. - created logos branding materials. education: - bachelor fine arts graphic design, art institute (2015 - 2019) skills: - tools: adobe photoshop, illustrator, indesign - design: branding, print design, digital design', 'john doe johndoe@example.com experience: - software engineer techcorp (2018 - present) - developed maintained web applications using python javascript. - collaborated cross -functional teams design new features. - implemented restful apis improved database performance. education: - bachelor science computer science, university technology (2014 - 2018) skills: - programming languages: python, javascript, java - frameworks: django, react - tools: gi t, docker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just for testing purpose\n",
        "similarity(\"red\",\"pink\")"
      ],
      "metadata": {
        "id": "pKuqd4V-aIS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c5c4ca-4b8c-460c-f630-e3a0997dc74e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-9f733e515850>:4: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  similarity_score2=w1_adjs.similarity(w2_adjs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}